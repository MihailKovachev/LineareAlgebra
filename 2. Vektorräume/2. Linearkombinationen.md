# Linearkombination 

> [!danger] Definition: Linearkombination
> Eine *Linearkombination* von den Vektoren $\vec{v}_1, \vec{v}_2, \cdots, \vec{v}_n$ aus dem Vektorraum $(V, K, +, \cdot)$ is ein Vektor $\vec{v}$ der Form
> $$\vec{v} = k_1\vec{v}_1 + k_2\vec{v}_2 +\cdots + k_n\vec{v}_n, k_i \in K$$
	
> [!danger] Definition: Linearkombination einer unendlichen Menge
> Ein Vektor $\vec{v} \in V$ wird *Linearkombination* der unendlichen Menge $\lbrace\vec{v}_1, \vec{v}_2, \cdots\rbrace$ genannt, falls es endlich viele Vektoren $\vec{v}_{i_1}, \vec{v}_{i_2}, \cdots, \vec{v}_{i_n}\in \lbrace\vec{v}_1,\vec{v}_2,\cdots\rbrace$ und Skalare $k_{i_1}, k_{i_2}, \cdots, k_{i_n} \in K$ gibt mit
> $$\vec{v} = k_{i_1}\vec{v}_{i_1}+k_{i_2}\vec{v}_{i_2}+\cdots+k_{i_n}\vec{v}_{i_n}$$

## Lineare Unabhängigkeit

> [!danger] Definition: Lineare Unabhängigkeit
> Man nennt die Vektoren $\vec{v}_1,\vec{v}_2,\cdots, \vec{v}_n$ *linear unabhängig*, falls es gilt
> $$k_1\vec{v}_1+k_2\vec{v}_2 + \cdots + k_n\vec{v}_n= \vec{0} \implies k_1 = k_2 = \cdots = k_n = 0$$

> [!danger] Definition: Maximalität einer linear unabhängigen Menge 
> Eine Menge $B \subseteq V$ linear unabhängiger Vektoren $\vec{v}_1,\vec{v}_2,\cdots$ heißt *maximal*, wenn es keinen Vektor $\vec{v} \in (V - B)$ gibt, so dass $\lbrace\vec{v}\rbrace \cup B$ immer noch linear unabhängig ist.

> [!important] Satz: Koeffizientenvergleich
> Seien $\vec{v}_1,\vec{v}_2,\cdots,\vec{v}_n$ linear unabhängige Vektoren, dann gilt
> $$k_1\vec{v}_1 + k_2\vec{v}_2 + \cdots + k_n\vec{v}_n = k_1'\vec{v}_1 + k_2'\vec{v}_2 + \cdots + k_n'\vec{v}_n \implies k_1=k_1', k_2=k_2',\cdots,k_n=k_n'$$
> > [!check]- Beweis
> > $$k_1\vec{v}_1 + k_2\vec{v}_2 + \cdots + k_n\vec{v}_n = k_1'\vec{v}_1 + k_2'\vec{v}_2 + \cdots + k_n'\vec{v}_n \implies (k_1-k_1')\vec{v}_1 + (k_2-k_2')\vec{v}_2 + \cdots + (k_n-k_n')\vec{v}_n = \vec{0}$$
> > Da die Vektoren linear unabhängig sind, müssen die Koeffizienten davor alle Null sein. Also muss $k_i-k_i' = 0, \forall i \in \lbrace1,2,\cdots, n\rbrace$ gelten.

## Lineare Abhängigkeit

> [!danger] Definition: Lineare Abhängigkeit
> Die Vektoren $\vec{v}_1,\vec{v}_2,\cdots$ sind *linear abhängig*, falls sie nicht linear unabhängig sind, d.h. die Vektoren $\vec{v}_1,\vec{v}_2,\cdots, \vec{v}_n$ sind genau dann linear abhängig, wenn es Skalare $k_1, k_2,\cdots,k_n$ gibt, von denen nicht alle Null sind, mit
> $$k_1\vec{v}_1+k_2\vec{v}_2+\cdots+k_n\vec{n} = \vec{0}$$
	
> [!important] Satz: Linearkombination aus linearer Abhängigkeit
> In jeder Folge $\vec{v}_1,\vec{v}_2,\cdots,\vec{v}_n$ linear abhängiger Vektoren ($n\ge 2$), gibt es *mindestens einen* Vektor $\vec{v}_i, i \in \lbrace1,2,\cdots,n\rbrace$, der sich als Linearkombination der anderen Vektoren darstellen lässt, also
> $$\vec{v}_i = \sum_{j\ne i} - \frac{k_j}{k_i} \vec{v}_j$$
> > [!check]- Beweis
> > Nach Definition der linearen Abhängigkeit gibt es $k_1,k_2,\cdots,k_n \in K$ mit
> > $$k_1\vec{v}_1+k_2\vec{v}_2+\cdots+k_n\vec{n} = \vec{0}$$
> > so, dass mindestens einer der Koeffizienten, den wir $k_i$ nennen, ungleich Null ist. Dann folgt
> > $$k_i\vec{v}_i = -k_1\vec{v}_1-k_2\vec{v}_2 + \cdots -k_{i-1}\vec{v}_{i-1}-k_{i+1}\vec{v}_{i+1}+\cdots -k_n\vec{v}_n$$
> > Da $k_i\ne 0$, folgt
> > $$\vec{v}_i = -\frac{k_1}{k_i}\vec{v}_1-\frac{k_2}{k_i}\vec{v}_2 + \cdots -\frac{k_{i-1}}{k_i}\vec{v}_{i-1}-\frac{k_{i+1}}{k_i}\vec{v}_{i+1}+\cdots -\frac{k_n}{k_i}\vec{v}_n$$

# Erzeugnis

> [!danger] Definition: Erzeugnis
> Das *Erzeugnis* (bezeichnet durch $\langle\lbrace\vec{v}_1,\vec{v}_2,\cdots\rbrace\rangle$ oder einfach $\langle\vec{v}_1,\vec{v}_2,\cdots\rangle$) der Vektoren $\vec{v}_1,\vec{v}_2,\dots$ nennt man die Menge aller Linearkombinationen, die mit $\vec{v}_1,\vec{v}_2,\dots$ gebildet werden können.